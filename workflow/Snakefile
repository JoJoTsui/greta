from snakemake.utils import min_version
min_version('7.29.0')
import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(os.path.curdir), 'workflow', 'scripts', 'anl')))
from itertools import combinations
home_path = os.path.expanduser("~")


def map_rules(rule_prefix, w_name, out='out'):
    rule_name=f'{rule_prefix}_{w_name}'
    if hasattr(rules, rule_name):
        return getattr(rules, rule_name).output[out]
    else:
        print(f'rule_prefix={rule_prefix} w_name={w_name}, out={out}, rule_name={rule_name}')


def format_rule(out, w, pre, p2g=None, tfb=None, mdl=None, resource=None):
    if (p2g is None) & (tfb is None) & (mdl is None):
        p2g, tfb, mdl = pre, pre, pre
    frm = out.format(
        pre=pre,
        p2g=p2g,
        tfb=tfb,
        mdl=mdl,
        **w
    )
    return frm


def _resolve_metric_rule(rule_name):
    base_name = rule_name.replace('/', '_')
    segments = base_name.split('_')
    for end_idx in range(len(segments), 0, -1):
        cand = '_'.join(segments[:end_idx])
        try:
            return getattr(rules, cand)
        except Exception:
            continue
    raise ValueError(f"Unable to map rule_name '{rule_name}' to a defined rule")


def make_combs_rules(w, mthds, baselines, rule_name):
    from itertools import product
    resolved_rule = _resolve_metric_rule(rule_name)
    out = resolved_rule.output.out
    rule_outputs = []
    if w.dat not in nocombs_datasets:
        # Original code generating all combinations:
        for pre, p2g, tfb, mdl in product(mthds, repeat=4):
            rule_outputs.append(
                format_rule(out, w=w, pre=pre, p2g=p2g, tfb=tfb, mdl=mdl)
            )
        # Modified code to generate only consistent combinations:
        # for mth in mthds:
        #      rule_outputs.append(
        #          format_rule(out, w=w, pre=mth, p2g=mth, tfb=mth, mdl=mth)
        #      )
    else:
        # This part handles datasets where combinations are not needed, keep as is
        for mth in mthds:
            rule_outputs.append(format_rule(out, w=w, pre=mth))
    # Keep the logic for 'o_' prefixed methods (original method runs)
    for mth in mthds:
        rule_outputs.append(format_rule(out, w=w, pre='o_' + mth))
    # Keep the logic for baselines (currently empty based on previous context)
    for bsl in baselines:
        rule_outputs.append(format_rule(out, w=w, pre=bsl))
    return rule_outputs


def make_consistent_rules(w, mthds, baselines, rule_name):
    resolved_rule = _resolve_metric_rule(rule_name)
    out = resolved_rule.output.out
    rule_outputs = []
    for mth in mthds:
        rule_outputs.append(
            format_rule(out, w=w, pre=mth, p2g=mth, tfb=mth, mdl=mth)
        )
    for mth in mthds:
        rule_outputs.append(format_rule(out, w=w, pre='o_' + mth))
    for bsl in baselines:
        rule_outputs.append(format_rule(out, w=w, pre=bsl))
    return rule_outputs


def make_metric_inputs(w, mthds, baselines, rule_name):
    if getattr(w, 'case', None) == 'tcell':
        return make_consistent_rules(w=w, mthds=mthds, baselines=baselines, rule_name=rule_name)
    return make_combs_rules(w=w, mthds=mthds, baselines=baselines, rule_name=rule_name)


def list_frags_files(wildcards):
    return expand('dts/{dat}/{smp}.frags.tsv.gz',
                    dat=wildcards.dat,
                    smp=config['dts'][wildcards.dat]['samples'])


def restart_mem(wildcards, attempt):
    mem = (2 ** (4 + attempt)) * 1000
    if wildcards.dat in big_datasets:
        mem = mem * 2
    return mem


def prior_metric_targets(dat, case):
    """Collect aggregate prior metric targets for a dataset/case pair."""
    # Restrict databases for tcell case to match detailed rule
    if case == 'tcell':
        tfm_dbs = ['hpa', 'tfmdb']
        tfp_dbs = ['intact']
        # Skip tfb, c2g, cre for direct comparison
        targets = []
        targets.extend(
            expand(
                'anl/metrics/prior/tfm/{db}/{dat}.{case}.scores.csv',
                db=tfm_dbs,
                dat=dat,
                case=case,
            )
        )
        targets.extend(
            expand(
                'anl/metrics/prior/tfp/{db}/{dat}.{case}.scores.csv',
                db=tfp_dbs,
                dat=dat,
                case=case,
            )
        )
        # Deduplicate while preserving deterministic ordering
        return sorted(set(targets))
    else:
        tfm_dbs = list(config['dbs']['hg38']['tfm'].keys())
        tfp_dbs = [k for k in config['dbs']['hg38']['tfp'].keys() if k != 'europmc']
        tfb_dbs = [k for k in config['dbs']['hg38']['tfb'].keys() if k != 'chipatlas']
        c2g_dbs = list(config['dbs']['hg38']['c2g'].keys())
        targets = []
        targets.extend(
            expand(
                'anl/metrics/prior/tfm/{db}/{dat}.{case}.scores.csv',
                db=tfm_dbs,
                dat=dat,
                case=case,
            )
        )
        targets.extend(
            expand(
                'anl/metrics/prior/tfp/{db}/{dat}.{case}.scores.csv',
                db=tfp_dbs,
                dat=dat,
                case=case,
            )
        )
        targets.extend(
            expand(
                'anl/metrics/prior/tfb/{db}/{dat}.{case}.scores.csv',
                db=tfb_dbs,
                dat=dat,
                case=case,
            )
        )
        targets.extend(
            expand(
                'anl/metrics/prior/c2g/{db}/{dat}.{case}.scores.csv',
                db=c2g_dbs,
                dat=dat,
                case=case,
            )
        )
        targets.extend(
            expand(
                'anl/metrics/prior/cre/{db}/{dat}.{case}.scores.csv',
                db=['fantom5', 'screen'],
                dat=dat,
                case=case,
            )
        )
        # Deduplicate while preserving deterministic ordering
        return sorted(set(targets))


def prior_metric_targets_detailed(dat, case):
    """Collect detailed prior metric targets (with TP/FP/FN) - PARALLEL VERSION."""
    # Focus on specific databases: hpa, tfmdb (tfm), intact (tfp)
    tfm_dbs = ['hpa', 'tfmdb']
    tfp_dbs = ['intact']
    
    targets = []
    
    # Add metric scores for tfm databases
    targets.extend(
        expand(
            'anl/metrics/prior_detailed/tfm/{db}/{dat}.{case}.scores.csv',
            db=tfm_dbs,
            dat=dat,
            case=case,
        )
    )
    
    # Add metric scores for tfp databases
    targets.extend(
        expand(
            'anl/metrics/prior_detailed/tfp/{db}/{dat}.{case}.scores.csv',
            db=tfp_dbs,
            dat=dat,
            case=case,
        )
    )
    
    # Add confusion matrix outputs (TP/FP/FN) for tfm
    targets.extend(
        expand(
            'anl/metrics/prior_detailed/tfm/{db}/{dat}.{case}.confusion_agg.csv',
            db=tfm_dbs,
            dat=dat,
            case=case,
        )
    )
    
    # Add confusion matrix outputs (TP/FP/FN) for tfp
    targets.extend(
        expand(
            'anl/metrics/prior_detailed/tfp/{db}/{dat}.{case}.confusion_agg.csv',
            db=tfp_dbs,
            dat=dat,
            case=case,
        )
    )
    
    # Note: Cell-type-specific database subsets are created as side effects
    # by the tfm_detailed.py script but are not tracked as Snakemake outputs
    # They will be saved to: anl/metrics/prior_detailed/tfm/{db}/{dat}.{case}.subset.csv
    
    # Deduplicate while preserving deterministic ordering
    return sorted(set(targets))


configfile: 'config/config.yaml'

orgms = [k for k in config['dbs'] if k != 'ont']
# mthds = [m for m in list(config['methods'].keys())] # Original line
mthds = ['scenicplus', 'dictys'] # Keep only scenicplus and dictys
# baselines = config['baselines']
baselines = []

datasets = list(config['dts'].keys())
stab_datasets = config['stab_datasets']
nocombs_datasets = config['nocombs_datasets']
big_datasets = config['big_datasets']

# Get singularities
include: 'rules/img/img.smk'

# Databases
include: 'rules/dbs/gen.smk'
include: 'rules/dbs/ont.smk'
include: 'rules/dbs/tfm.smk'
include: 'rules/dbs/tfb.smk'
include: 'rules/dbs/tfp.smk'
include: 'rules/dbs/cre.smk'
include: 'rules/dbs/tss.smk'
include: 'rules/dbs/gst.smk'
include: 'rules/dbs/c2g.smk'
include: 'rules/dbs/prt.smk'

# Datasets
include: 'rules/dts/pbmc10k.smk'
# include: 'rules/dts/reprofibro.smk'
# include: 'rules/dts/pitupair.smk'
# include: 'rules/dts/pitunpair.smk'
# include: 'rules/dts/fakepair.smk'
# include: 'rules/dts/heartatlas.smk'
# include: 'rules/dts/brain.smk'
include: 'rules/dts/general.smk'

# Methods
include: 'rules/mth/celloracle.smk'
include: 'rules/mth/dictys.smk'
include: 'rules/mth/pando.smk'
include: 'rules/mth/granie.smk'
include: 'rules/mth/figr.smk'
include: 'rules/mth/scenicplus.smk'
include: 'rules/mth/grn.smk'
include: 'rules/mth/random.smk'
include: 'rules/mth/scenic.smk'

# Analyses
include: 'rules/anl/metrics/prior.smk'
include: 'rules/anl/metrics/pred.smk'
include: 'rules/anl/metrics/mech.smk'
include: 'rules/anl/metrics/utils.smk'
include: 'rules/anl/topo.smk'
include: 'rules/anl/stab.smk'
include: 'rules/anl/pair.smk'
include: 'rules/anl/tss.smk'
include: 'rules/anl/dbs.smk'
include: 'rules/anl/dts.smk'

# Plots
include: 'rules/plt/stab.smk'
include: 'rules/plt/pair.smk'
include: 'rules/plt/comb.smk'
include: 'rules/plt/dbs.smk'
include: 'rules/plt/eval.smk'
include: 'rules/plt/figs.smk'



rule download_databases:
    input:
        # c2g outputs
        # "dbs/hg38/c2g/eqtlcatalogue/meta.tsv",
        # "dbs/hg38/c2g/eqtlcatalogue/eqtlcatalogue.bed",
        # "dbs/hg38/c2g/links.tsv.gz",
        # cre outputs
        "dbs/hg38/cre/blacklist/blacklist.bed",
        "dbs/hg38/cre/encode/encode.bed",
        "dbs/hg38/cre/gwascatalogue/gwascatalogue.bed",
        # "dbs/hg38/cre/phastcons/phastcons.bed",
        "dbs/hg38/cre/promoters/promoters.bed",
        "dbs/hg38/cre/zhang21/zhang21.bed",
        # gen outputs
        "dbs/hg38/gen/tfs/lambert.csv",
        "dbs/hg38/gen/tfs/scenic.csv",
        "dbs/hg38/gen/gid/ensembl.csv",
        "dbs/hg38/gen/pid/uniprot.csv",
        # "dbs/hg38/gen/genome/celloracle/",
        # "dbs/hg38/gen/genome/dictys/",
        "dbs/hg38/gen/genome/scenicplus/annotation.tsv",
        "dbs/hg38/gen/genome/scenicplus/chromsizes.tsv",
        "dbs/hg38/gen/genome/scenicplus/tss.tsv",
        # "dbs/hg38/gen/motif/granie/",
        "dbs/hg38/gen/motif/dictys/dictys.motif",
        "dbs/hg38/gen/motif/scenic/hg38_500bp_up_100bp_down_full_tx_v10_clust.genes_vs_motifs.rankings.feather",
        "dbs/hg38/gen/motif/scenic/hg38_10kbp_up_10kbp_down_full_tx_v10_clust.genes_vs_motifs.rankings.feather",
        "dbs/hg38/gen/motif/scenic/nr.hgnc-m0.001-o0.0.tbl",
        # "dbs/hg38/gen/motif/scenicplus/human_motif_SCREEN.regions_vs_motifs.rankings.feather",
        # "dbs/hg38/gen/motif/scenicplus/human_motif_SCREEN.regions_vs_motifs.scores.feather",
        "dbs/hg38/gen/motif/scenicplus/motifs-v10nr_clust/nr.hgnc-m0.001-o0.0.tbl",
        # gst outputs
        "dbs/hg38/gst/collectri.csv",
        "dbs/hg38/gst/dorothea.csv",
        "dbs/hg38/gst/prog.csv",
        # ont outputs
        "dbs/ont/bto.tsv",
        # prt outputs
        "dbs/hg38/prt/knocktf/meta.csv",
        "dbs/hg38/prt/knocktf/diff.csv",
        # tfb outputs
        "dbs/hg38/tfb/chipatlas/meta.tsv",
        # "dbs/hg38/tfb/chipatlas/chipatlas.bed",
        "dbs/hg38/tfb/remap2022/meta.tsv",
        "dbs/hg38/tfb/remap2022/remap2022.bed",
        "dbs/hg38/tfb/unibind/unibind.bed",
        # tfm outputs
        "dbs/hg38/tfm/hpa/hpa.tsv",
        "dbs/hg38/tfm/tfmdb/tfmdb.tsv",
        # tfp outputs
        "dbs/hg38/tfp/intact/intact.tsv",
        # "dbs/hg38/tfp/europmc/europmc.tsv",
        # tss outputs
        "dbs/hg38/gen/tss/celloracle.bed",
        "dbs/hg38/gen/tss/dictys.bed",
        # "dbs/hg38/gen/tss/figr.bed",
        # "dbs/hg38/gen/tss/pando.bed",
        # "dbs/hg38/gen/tss/granie.bed",
        "dbs/hg38/gen/tss/scenicplus.bed",
        "dbs/hg38/gen/tss/collectri.bed",
        "dbs/hg38/gen/tss/dorothea.bed",
        "dbs/hg38/gen/tss/random.bed",
        "dbs/hg38/gen/tss/scenic.bed",
        # anl/dbs outputs
        "anl/dbs/stats.csv",
        "anl/dbs/terms.csv",
    output:
        touch("results/databases_downloaded.flag")
    shell:
        "touch {output}"

# --- End of modified code ---

rule prepare_pbmc10k:
    input:
        'dts/pbmc10k/annotated.h5mu',
        qc='anl/dts/pbmc10k.all.qc.csv',
        nc='anl/dts/pbmc10k.all.nc.csv'


rule run_dictys_pbmc10k_all:
    input:
        'dts/pbmc10k/cases/all/runs/dictys.dictys.dictys.dictys.grn.csv'

rule run_scenicplus_pbmc10k_all:
    input:
        'dts/pbmc10k/cases/all/runs/scenicplus.scenicplus.scenicplus.scenicplus.grn.csv'

rule run_scenicplus_dictys_tcell:
    input:
        'dts/pbmc10k/cases/tcell/runs/scenicplus.scenicplus.scenicplus.scenicplus.grn.csv',
        'dts/pbmc10k/cases/tcell/runs/dictys.dictys.dictys.dictys.grn.csv',
        'dts/pbmc10k/cases/tcell/runs/o_scenicplus.o_scenicplus.o_scenicplus.o_scenicplus.mdl.csv',
        'dts/pbmc10k/cases/tcell/runs/o_dictys.o_dictys.o_dictys.o_dictys.mdl.csv'


# Helper marker to force Snakemake to revisit aggregate prior metrics each run
rule benchmark_prior_ready:
    input:
        lambda w: prior_metric_targets(dat=w.dat, case=w.case)
    output:
        ready=temp('results/.benchmark_prior.{dat}.{case}.ready')
    shell:
        "touch {output.ready}"


# --- Start of new rule ---

rule benchmark_prior_pbmc10k_specific:
    input:
        prior_ready='results/.benchmark_prior.pbmc10k.all.ready',
        summary='anl/metrics/summary/pbmc10k.all.csv'
    output:
        touch("results/benchmark_prior_pbmc10k_specific.flag")
    shell:
        "touch {output}"

# --- End of new rule ---


rule benchmark_prior_pbmc10k_tcell:
    input:
        rules.run_scenicplus_dictys_tcell.input,
        prior_ready='results/.benchmark_prior.pbmc10k.tcell.ready',
        summary='anl/metrics/summary/pbmc10k.tcell.csv'  # Commented out to skip dbs_stats/dbs_terms dependencies
    output:
        touch("results/benchmark_prior_pbmc10k_tcell.flag")
    shell:
        "touch {output}"


# ============ NEW PARALLEL RULES FOR DETAILED ANALYSIS ============

rule benchmark_prior_detailed_pbmc10k:
    """
    NEW PARALLEL RULE: Benchmark prior metrics with detailed TP/FP/FN analysis
    Focuses on hpa, tfmdb, and intact databases
    Outputs: scores, confusion matrices, and cell-type-specific subsets
    """
    input:
        lambda wildcards: prior_metric_targets_detailed('pbmc10k', 'all')
    output:
        touch('results/benchmark_prior_detailed_pbmc10k.flag')


rule benchmark_prior_detailed_pbmc10k_tcell:
    """
    NEW PARALLEL RULE: Benchmark prior metrics for T cell case with detailed analysis
    """
    input:
        lambda wildcards: prior_metric_targets_detailed('pbmc10k', 'tcell')
    output:
        touch('results/benchmark_prior_detailed_pbmc10k_tcell.flag')


rule all:
    input:
        # 'results/databases_downloaded.flag',  # Commented out to skip c2g_eqtlcatalogue, dbs_stats, dbs_terms
        rules.benchmark_prior_pbmc10k_specific.output, # Commented out to skip dbs_stats/dbs_terms
        rules.benchmark_prior_pbmc10k_tcell.output,
        # Add other final desired outputs of the workflow
        # Optionally add the new scenicplus output here if it should be part of the default 'all' target
        # rules.run_scenicplus_pbmc10k_all.input,
        # Optionally add the QC results to the default 'all' target
        # rules.qc_pbmc10k_all.input,
        ''

# snakemake --profile config/slurm/ --notemp ...
