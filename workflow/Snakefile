from snakemake.utils import min_version
min_version('7.29.0')
import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(os.path.curdir), 'workflow', 'scripts', 'anl')))
from itertools import combinations
home_path = os.path.expanduser("~")


def map_rules(rule_prefix, w_name, out='out'):
    rule_name=f'{rule_prefix}_{w_name}'
    if hasattr(rules, rule_name):
        return getattr(rules, rule_name).output[out]
    else:
        print(f'rule_prefix={rule_prefix} w_name={w_name}, out={out}, rule_name={rule_name}')


def format_rule(out, w, pre, p2g=None, tfb=None, mdl=None, resource=None):
    if (p2g is None) & (tfb is None) & (mdl is None):
        p2g, tfb, mdl = pre, pre, pre
    frm = out.format(
        pre=pre,
        p2g=p2g,
        tfb=tfb,
        mdl=mdl,
        **w
    )
    return frm


def make_combs_rules(w, mthds, baselines, rule_name):
    from itertools import product
    out = getattr(rules, rule_name).output.out
    rule_outputs = []
    if w.dat not in nocombs_datasets:
        # Original code generating all combinations:
        for pre, p2g, tfb, mdl in product(mthds, repeat=4):
            rule_outputs.append(
                format_rule(out, w=w, pre=pre, p2g=p2g, tfb=tfb, mdl=mdl)
            )
        # Modified code to generate only consistent combinations:
        # for mth in mthds:
        #      rule_outputs.append(
        #          format_rule(out, w=w, pre=mth, p2g=mth, tfb=mth, mdl=mth)
        #      )
    else:
        # This part handles datasets where combinations are not needed, keep as is
        for mth in mthds:
            rule_outputs.append(format_rule(out, w=w, pre=mth))
    # Keep the logic for 'o_' prefixed methods (original method runs)
    for mth in mthds:
        rule_outputs.append(format_rule(out, w=w, pre='o_' + mth))
    # Keep the logic for baselines (currently empty based on previous context)
    for bsl in baselines:
        rule_outputs.append(format_rule(out, w=w, pre=bsl))
    return rule_outputs


def list_frags_files(wildcards):
    return expand('dts/{dat}/{smp}.frags.tsv.gz',
                    dat=wildcards.dat,
                    smp=config['dts'][wildcards.dat]['samples'])


def restart_mem(wildcards, attempt):
    mem = (2 ** (4 + attempt)) * 1000
    if wildcards.dat in big_datasets:
        mem = mem * 2
    return mem


configfile: 'config/config.yaml'

orgms = [k for k in config['dbs'] if k != 'ont']
# mthds = [m for m in list(config['methods'].keys())] # Original line
mthds = ['scenicplus', 'dictys'] # Keep only scenicplus and dictys
# baselines = config['baselines']
baselines = []

datasets = list(config['dts'].keys())
stab_datasets = config['stab_datasets']
nocombs_datasets = config['nocombs_datasets']
big_datasets = config['big_datasets']

# Get singularities
include: 'rules/img/img.smk'

# Databases
include: 'rules/dbs/gen.smk'
include: 'rules/dbs/ont.smk'
include: 'rules/dbs/tfm.smk'
include: 'rules/dbs/tfb.smk'
include: 'rules/dbs/tfp.smk'
include: 'rules/dbs/cre.smk'
include: 'rules/dbs/tss.smk'
include: 'rules/dbs/gst.smk'
include: 'rules/dbs/c2g.smk'
include: 'rules/dbs/prt.smk'

# Datasets
include: 'rules/dts/pbmc10k.smk'
# include: 'rules/dts/reprofibro.smk'
# include: 'rules/dts/pitupair.smk'
# include: 'rules/dts/pitunpair.smk'
# include: 'rules/dts/fakepair.smk'
# include: 'rules/dts/heartatlas.smk'
# include: 'rules/dts/brain.smk'
include: 'rules/dts/general.smk'

# Methods
include: 'rules/mth/celloracle.smk'
include: 'rules/mth/dictys.smk'
include: 'rules/mth/pando.smk'
include: 'rules/mth/granie.smk'
include: 'rules/mth/figr.smk'
include: 'rules/mth/scenicplus.smk'
include: 'rules/mth/grn.smk'
include: 'rules/mth/random.smk'
include: 'rules/mth/scenic.smk'

# Analyses
include: 'rules/anl/metrics/prior.smk'
include: 'rules/anl/metrics/pred.smk'
include: 'rules/anl/metrics/mech.smk'
include: 'rules/anl/metrics/utils.smk'
include: 'rules/anl/topo.smk'
include: 'rules/anl/stab.smk'
include: 'rules/anl/pair.smk'
include: 'rules/anl/tss.smk'
include: 'rules/anl/dbs.smk'
include: 'rules/anl/dts.smk'

# Plots
include: 'rules/plt/stab.smk'
include: 'rules/plt/pair.smk'
include: 'rules/plt/comb.smk'
include: 'rules/plt/dbs.smk'
include: 'rules/plt/eval.smk'
include: 'rules/plt/figs.smk'



rule download_databases:
    input:
        # c2g outputs
        "dbs/hg38/c2g/eqtlcatalogue/meta.tsv",
        "dbs/hg38/c2g/eqtlcatalogue/eqtlcatalogue.bed",
        "dbs/hg38/c2g/links.tsv.gz",
        # cre outputs
        "dbs/hg38/cre/blacklist/blacklist.bed",
        "dbs/hg38/cre/encode/encode.bed",
        "dbs/hg38/cre/gwascatalogue/gwascatalogue.bed",
        # "dbs/hg38/cre/phastcons/phastcons.bed",
        "dbs/hg38/cre/promoters/promoters.bed",
        "dbs/hg38/cre/zhang21/zhang21.bed",
        # gen outputs
        "dbs/hg38/gen/tfs/lambert.csv",
        "dbs/hg38/gen/tfs/scenic.csv",
        "dbs/hg38/gen/gid/ensembl.csv",
        "dbs/hg38/gen/pid/uniprot.csv",
        # "dbs/hg38/gen/genome/celloracle/",
        # "dbs/hg38/gen/genome/dictys/",
        "dbs/hg38/gen/genome/scenicplus/annotation.tsv",
        "dbs/hg38/gen/genome/scenicplus/chromsizes.tsv",
        "dbs/hg38/gen/genome/scenicplus/tss.tsv",
        # "dbs/hg38/gen/motif/granie/",
        "dbs/hg38/gen/motif/dictys/dictys.motif",
        "dbs/hg38/gen/motif/scenic/hg38_500bp_up_100bp_down_full_tx_v10_clust.genes_vs_motifs.rankings.feather",
        "dbs/hg38/gen/motif/scenic/hg38_10kbp_up_10kbp_down_full_tx_v10_clust.genes_vs_motifs.rankings.feather",
        "dbs/hg38/gen/motif/scenic/nr.hgnc-m0.001-o0.0.tbl",
        # "dbs/hg38/gen/motif/scenicplus/human_motif_SCREEN.regions_vs_motifs.rankings.feather",
        # "dbs/hg38/gen/motif/scenicplus/human_motif_SCREEN.regions_vs_motifs.scores.feather",
        "dbs/hg38/gen/motif/scenicplus/motifs-v10nr_clust/nr.hgnc-m0.001-o0.0.tbl",
        # gst outputs
        "dbs/hg38/gst/collectri.csv",
        "dbs/hg38/gst/dorothea.csv",
        "dbs/hg38/gst/prog.csv",
        # ont outputs
        "dbs/ont/bto.tsv",
        # prt outputs
        "dbs/hg38/prt/knocktf/meta.csv",
        "dbs/hg38/prt/knocktf/diff.csv",
        # tfb outputs
        "dbs/hg38/tfb/chipatlas/meta.tsv",
        # "dbs/hg38/tfb/chipatlas/chipatlas.bed",
        "dbs/hg38/tfb/remap2022/meta.tsv",
        "dbs/hg38/tfb/remap2022/remap2022.bed",
        "dbs/hg38/tfb/unibind/unibind.bed",
        # tfm outputs
        "dbs/hg38/tfm/hpa/hpa.tsv",
        "dbs/hg38/tfm/tfmdb/tfmdb.tsv",
        # tfp outputs
        "dbs/hg38/tfp/intact/intact.tsv",
        # "dbs/hg38/tfp/europmc/europmc.tsv",
        # tss outputs
        "dbs/hg38/gen/tss/celloracle.bed",
        "dbs/hg38/gen/tss/dictys.bed",
        # "dbs/hg38/gen/tss/figr.bed",
        # "dbs/hg38/gen/tss/pando.bed",
        # "dbs/hg38/gen/tss/granie.bed",
        "dbs/hg38/gen/tss/scenicplus.bed",
        "dbs/hg38/gen/tss/collectri.bed",
        "dbs/hg38/gen/tss/dorothea.bed",
        "dbs/hg38/gen/tss/random.bed",
        "dbs/hg38/gen/tss/scenic.bed",
        # anl/dbs outputs
        "anl/dbs/stats.csv",
        "anl/dbs/terms.csv",
    output:
        touch("results/databases_downloaded.flag")
    shell:
        "touch {output}"

# --- End of modified code ---

rule prepare_pbmc10k:
    input:
        'dts/pbmc10k/annotated.h5mu',
        qc='anl/dts/pbmc10k.all.qc.csv',
        nc='anl/dts/pbmc10k.all.nc.csv'


rule run_dictys_pbmc10k_all:
    input:
        'dts/pbmc10k/cases/all/runs/dictys.dictys.dictys.dictys.grn.csv'

rule run_scenicplus_pbmc10k_all:
    input:
        'dts/pbmc10k/cases/all/runs/scenicplus.scenicplus.scenicplus.scenicplus.grn.csv'

rule run_scenicplus_dictys_all:
    input:
        'dts/pbmc10k/cases/all/runs/scenicplus.scenicplus.scenicplus.dictys.mdl.csv'

# --- Start of new rule ---

rule benchmark_prior_pbmc10k_specific:
    input:
        # Prior TFM metrics for pbmc10k.all
        expand('anl/metrics/prior/tfm/{db}/pbmc10k.all.scores.csv',
               db=config['dbs']['hg38']['tfm'].keys()),
        # Prior TFP metrics for pbmc10k.all (excluding europmc)
        expand('anl/metrics/prior/tfp/{db}/pbmc10k.all.scores.csv',
               db=[k for k in config['dbs']['hg38']['tfp'].keys() if k != 'europmc']),
        # Prior TFB metrics for pbmc10k.all (excluding chipatlas)
        expand('anl/metrics/prior/tfb/{db}/pbmc10k.all.scores.csv',
               db=[k for k in config['dbs']['hg38']['tfb'].keys() if k != 'chipatlas']),
        # Prior CRE metrics for pbmc10k.all
        expand('anl/metrics/prior/cre/{db}/pbmc10k.all.scores.csv',
               db=config['dbs']['hg38']['cre'].keys()),
        # Prior C2G metrics for pbmc10k.all
        expand('anl/metrics/prior/c2g/{db}/pbmc10k.all.scores.csv',
               db=config['dbs']['hg38']['c2g'].keys()),
        # Pior summary metrics for pbmc10k.all
        'anl/metrics/summary/pbmc10k.all.csv',
    output:
        touch("results/benchmark_prior_pbmc10k_specific.flag")
    shell:
        "touch {output}"

# --- End of new rule ---


rule all:
    input:
        'results/databases_downloaded.flag',
        rules.benchmark_prior_pbmc10k_specific.output, # Added the new target flag
        # Add other final desired outputs of the workflow
        # Optionally add the new scenicplus output here if it should be part of the default 'all' target
        # rules.run_scenicplus_pbmc10k_all.input,
        # Optionally add the QC results to the default 'all' target
        # rules.qc_pbmc10k_all.input,
        ''

# snakemake --profile config/slurm/ --notemp ...
